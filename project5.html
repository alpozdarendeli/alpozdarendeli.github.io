<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            max-width: 1200px;
            margin: 0 auto;
            background-color: #f4f4f4;
            color: #333;
        }
        h1, h2 {
            color: #2c3e50;
        }
        h1 {
            border-bottom: 2px solid #2c3e50;
            padding-bottom: 10px;
        }
        .project-overview {
            background-color: #fff;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        .image-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image-griddd {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image {
            display: flex;
            justify-content: center;
            align-items: center;
            margin-bottom: 20px;
        }
        .image img {
            max-width: 150%;
            width: 150%;
            height: auto;
        }
        .image-gri {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image-gr {
            display: grid;
            grid-template-columns: repeat(1, 1fr);
            gap: 15px;
            margin-bottom: 20px;
            justify-items: center; 
            align-items: center; 
        }
        .image-g {
            display: grid;
            grid-template-columns: repeat(6, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image-container {
            background-color: #fff;
            padding: 10px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 3px;
        }
        .image-subtitle {
            margin-top: 8px;
            font-style: italic;
            font-size: 0.9em;
            color: #555;
        }
        .clear-float {
            clear: both;
            width: 100%;
        }
        .image-description {
            margin-top: 8px;
            font-style: italic;
            font-size: 0.9em;
            color: #555;
        }
                
        .equation {
            margin: 20px 0;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <h1>Project 5: Fun With Diffusion Models!</h1>
    <h2>Alp Eren Ozdarendeli</h2>

    <div class="Background">
        <h1>Part A</h2>
    </div>
    
    <div class="project-overview">
        <h2>Part 0: Setup</h2>
            <p> For the setup part, I use DeepFloyd IF as the diffusion model. To test the setup, I used the given prompts to generate the following outputs:
        <div class="image-grid">
            <div class="image-container">
                <img src="images5/parta1_1.png" alt="taj.jpg">
                <p class="image-subtitle"> an oil painting of a snowy mountain village</p>
            </div>
            <div class="image-container">
                <img src="images5/parta1_4.png" alt="taj.jpg">
                <p class="image-subtitle"> a man wearing a hat</p>
            </div>
            <div class="image-container">
                <img src="images5/parta1_5.png" alt="taj.jpg">
                <p class="image-subtitle"> a rocket ship</p>
            </div>
        </div>
        <div class="clear-float"></div>
            <p> The generated images actually represent the prompts pretty well. To test the effect of num_inference_steps on the outputs, I test the prompt 'an oil painting of a snowy mountain village' with num_inference_steps 7 and 46 in addition to 20 given above. Here are outputs with num_inference_steps 7 and 46 respectively:<p>
            <div class="image-gri">
            <div class="image-container">
                <img src="images5/parta1_2.png" alt="taj.jpg">
                <p class="image-subtitle"> an oil painting of a snowy mountain village (num_inference_steps = 7)</p>
            </div>
            <div class="image-container">
                <img src="images5/parta1_3.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">an oil painting of a snowy mountain village (num_inference_steps = 46)</p>
            </div>
        </div>
        <div class="clear-float"></div>
        <p>With increasing num_inference_steps, the images become more detailed and better reflect the prompts.</p>
        <h2>1.1 Implementing the Forward Process</h2>
        <p>Now, I implement the forward process. For the forward process, given a clean image, I get a noisy image for a timestep t by sampling noise from a Gaussian. Also, I scale the image to 64 x 64 dimensions. The original Campanile image is shown below at different noise levels.<p>
        <div class="image-grid">
            <div class="image-container">
                <img src="images5/noise1.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=250</p>
            </div>
                        <div class="image-container">
                <img src="images5/noise2.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=500</p>
            </div>
                        <div class="image-container">
                <img src="images5/noise3.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=750</p>
            </div>
        </div>
        <div class="clear-float"></div>
        <h2>1.2 Classical Denoising</h2>
<p>For classical denoising I take a noisy image and try to denoise it by Gaussian filtering. Here are the results for different timestamps:</p>
        <div class="image-grid">
            <div class="image-container">
                <img src="images5/noise1.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=250</p>
            </div>
                        <div class="image-container">
                <img src="images5/noise2.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=500</p>
            </div>
                        <div class="image-container">
                <img src="images5/noise3.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=750</p>
            </div>
        </div>
        <div class="clear-float"></div>
                        <div class="image-grid">
            <div class="image-container">
                <img src="images5/cdns1.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Classical Denoised Campanile at t=250</p>
            </div>
                        <div class="image-container">
                <img src="images5/cdns2.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Classical Denoised Campanile at t=500</p>
            </div>
                        <div class="image-container">
                <img src="images5/cdns.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Classical Denoised Campanile at t=750</p>
            </div>
        </div>
        <div class="clear-float"></div>
    <h2>1.3 One-Step Denoising</h2>
    <p> For one-step denoising, I use a pretrained denoiser stage_1.unet to find the noise in the images. Then, I remove this image to recover a clean image:</p>
                <div class="image-grid">
            <div class="image-container">
                <img src="images5/noise1.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=250</p>
            </div>
                        <div class="image-container">
                <img src="images5/noise2.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=500</p>
            </div>
                        <div class="image-container">
                <img src="images5/noise3.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">Noisy Campanile at t=750</p>
            </div>
        </div>
        <div class="clear-float"></div>
                    <div class="image-grid">
            <div class="image-container">
                <img src="images5/odn1.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">One-Step Denoised Campanile at t=250</p>
            </div>
                        <div class="image-container">
                <img src="images5/odn2.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">One-Step Denoised Campanile at t=500</p>
            </div>
                        <div class="image-container">
                <img src="images5/odn3.png" alt="taj_sharp.jpg">
                <p class="image-subtitle">One-Step Denoised Campanile at t=750</p>
            </div>
        </div>
        <div class="clear-float"></div>
    <h2>Iterative Denoising</h2>
    <p> For iterative denoising, I create a new list of timesteps,strided_timesteps, to skip some steps. The stride of steps will be 30. In the following, denoised image is displayed at every fifth step and final clean image prediction is shown in comparison to other techniques:<p>
                    <div class="image-grid">
            <div class="image-container">
                <img src="images5/f1.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f2.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f3.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f4.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f5.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f6.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f7.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f8.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/f9.png" alt="taj_sharp.jpg">
            </div>
        </div>
        <div class="clear-float"></div>
        <h2>1.5 Diffusion Model Sampling </h2>
        <p> For this part, I use iterative denoising to generate images from scratch. I pass in random noise, and the function denoises pure noise. Here are 5 samples: </p>
                        <div class="image-griddd">
            <div class="image-container">
                <img src="images5/sample1.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/sample2.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/sample3.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/sample4.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/sample5.png" alt="taj_sharp.jpg">
            </div>
        </div>
        <div class="clear-float"></div>
        <h2>1.6 Classifier-Free Guidance (CFG)<h2>
        <p> The quality of the results in the previous section were not great. To significantly improve image quality, I will use CFG in this section. For CFG, I compute both conditional and unconditional noise estimate. In CFG, we have a hyperparameter, named scale in the function, that determines its strength. When scale is 0, CFG is essentially unconditional noise estimate but when scale is bigger than 1, I am able to produce much more quality images. Here are 5 samples from CFG with scale=7:</p>
                                        <div class="image-griddd">
            <div class="image-container">
                <img src="images5/cfg1.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/cfg2.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/cfg3.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/cfg4.png" alt="taj_sharp.jpg">
            </div>
                        <div class="image-container">
                <img src="images5/cfg5.png" alt="taj_sharp.jpg">
            </div>
        </div>
        <div class="clear-float"></div>
            <h1>Part B: Diffusion Models from Scratch</h1>
    <h2>Training a Single-Step Denoising UNet</h2>
    <p>For the second part of the project, I implement diffusion models from scratch. As a first step, I train single-sept denoising UNet. Firstly, I follow the model diagram for UNet to define its architecture. To train a denoiser with UNet, I use the image dataset from MNIST. Given a clean image, I add a random noise with sigma coefficient to create a noised image. Here are examples of noised images with different sigmas: </p>
    <div class="image-gr">
        <div class="image-container">
            <img src="images5/partbimage4.png" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
    <p> I train UNet to minimize the loss between denoised image from UNet given the noised image and the original clean image. Here are the sample results after training for 1 and 5 epochs:</p>
    <div class="image-gri">
        <div class="image-container">
            <img src="images5/partbimage1.png" alt="taj.jpg">
        </div>
        <div class="image-container">
            <img src="images5/partbimage2" alt="taj_sharp.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
    <p> In the training, I train the model for sigma = 0.5. Let's test how well it will perform for other sigma values:</p>
        <div class="image-gr">
        <div class="image-container">
            <img src="images5/partbimage3.png" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
    <p>Here is the training loss curve during the whole training process:</p>
    <div class="image-gr">
        <div class="image-container">
            <img src="images5/partbimage5.png" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
    <h2>Training a Diffusion Model</h2>
    <p>In this part, I will train a UNet model that iteratively denoises an image. For this, I will implement DDPM. </p>
    <p>Following the diagram and using FCBlocks, I inject time t into the UNet model for conditioning. </p>
    <div class="image-gr">
        <div class="image-container">
            <img src="proj4images/limitedharris.png" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
    <h2>Extracting Feature Descriptors</h2>
    <p> After identifying the features, now we have to extract feature descriptors. For each feature, we extract 40x40 windows, and downsample to get 8x8 patches. Before this step, low-pass Gaussian filter is applied. After getting the patches, each patch is normalized and reshaped to form 64 element feature descriptors for each feature. Here are some examples:</p>
    <div class="image-gri">
        <div class="image-container">
            <img src="proj4images/patch1.png" alt="taj.jpg">
        </div>
        <div class="image-container">
            <img src="proj4images/patch2.png" alt="taj_sharp.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
    <h2>Matching Feature Descriptors</h2>
    <p>After extracting the feature descriptors for each image, we need to match them. I created k-d trees for each image. I query the closest 2 pairwise feature vectors for each feature in one of the images. I calculated the L2 norm distance ratio of these 2 vectors to the original features. Using Lowe's trick, I only keep the closest feature vectors that have less a certain threshold distance ratio and also checked with the other tree to ensure that original feature vector is also the closest feature vector for the chosen feature. This greatly reduced the outliers, and here is the filtered matches: </p>
    <div class="image-gri">
        <div class="image-container">
            <img src="proj4images/features1.png" alt="taj.jpg">
        </div>
        <div class="image-container">
            <img src="proj4images/features2.png" alt="taj_sharp.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
    <h2>Robust method (RANSAC) to Compute Homography</h2>
    <p>To further reduce the outliers and inconsistencies, I implement the RANSAC algorithm. For 1000 iterations, I choose 4 matched point pairs and calculate homography based on them. Then, I calculated the inliners -- points that their transformed points are with a certain error threshold of their matched point in the other image-- for each computed homography. I determined the homography that yielded the most number of inliners, and recalculated the homography based on its all inline features.</p>
    
    <h2>Produce Mosaics</h2>
        <p>After computing homographies with RANSAC, I ran the same code that I used for part A to produce mosaics for the same 3 pictures. Here are the side-by-side manually and automatically stitched results for these images:</p>
        <div class="image-gri">
        <div class="image-container">
            <img src="proj4images/img3_ful.png" alt="taj.jpg">
            <p class="image-subtitle">Manual Stitching</p>
        </div>
        <div class="image-container">
            <img src="proj4images/auto1.png" alt="taj_sharp.jpg">
            <p class="image-subtitle">Automatic Stitching</p>
        </div>
        </div>
        <div class="clear-float"></div>
        <div class="image-gri">
        <div class="image-container">
            <img src="proj4images/mosaic1.png" alt="taj.jpg">
            <p class="image-subtitle">Manual Stitching</p>
        </div>
        <div class="image-container">
            <img src="proj4images/auto2.png" alt="taj_sharp.jpg">
            <p class="image-subtitle">Automatic Stitching</p>
        </div>
        </div>
        <div class="clear-float"></div>
                <div class="image-gri">
        <div class="image-container">
            <img src="proj4images/manual2.png" alt="taj.jpg">
            <p class="image-subtitle">Manual Stitching</p>
        </div>
        <div class="image-container">
            <img src="proj4images/auto3.png" alt="taj_sharp.jpg">
            <p class="image-subtitle">Automatic Stitching</p>
        </div>
        </div>
        <div class="clear-float"></div>
        <p> I think with automatic stitching, the results were better. I may have done a few slightly inaccurate point correspondences, and this may have affected manual stitching results. The coolest thing I learned while doing the project was implementing the RANSAC algorithm from scratch. Even though I took introduction to machine learning class before, I haven't had the chance to code RANSAC and I think it was cool to learn how to code its iterative consensus algorithm.</p>
    </div>
</body>
</html>
    </div>
</body>
</html>
