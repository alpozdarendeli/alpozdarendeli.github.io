<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            max-width: 1200px;
            margin: 0 auto;
            background-color: #f4f4f4;
            color: #333;
        }
        h1, h2 {
            color: #2c3e50;
        }
        h1 {
            border-bottom: 2px solid #2c3e50;
            padding-bottom: 10px;
        }
        .project-overview {
            background-color: #fff;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        .image-grrid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image-grrid img {
    width: 40%;
    height: 40%;
    object-fit: contain; 
}

        .image-griddd {
            display: grid;
            grid-template-columns: repeat(5, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
                .image-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
                .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 3px;
        }
        .image {
            display: flex;
            justify-content: center;
            align-items: center;
            margin-bottom: 20px;
        }
        .image-gri {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image-gr {
            display: grid;
            grid-template-columns: repeat(1, 1fr);
            gap: 15px;
            margin-bottom: 20px;
            justify-items: center; 
            align-items: center; 
        }
        .image-g {
            display: grid;
            grid-template-columns: repeat(7, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image-gi {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        .image-container {
            background-color: #fff;
            padding: 10px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .image-subtitle {
            margin-top: 8px;
            font-style: italic;
            font-size: 0.9em;
            color: #555;
        }
        .clear-float {
            clear: both;
            width: 100%;
        }
        .image-description {
            margin-top: 8px;
            font-style: italic;
            font-size: 0.9em;
            color: #555;
        }
                
        .equation {
            margin: 20px 0;
            overflow-x: auto;
        }
    </style>
</head>
<body>
<header>
  <nav class="navbar">
    <a href="index.html">Home</a>
    <a href="project1.html">Project 1</a>
    <a href="project2.html">Project 2</a>
    <a href="project3.html">Project 3</a>
    <a href="project4.html">Project 4</a>
    <a href="project5.html">Project 5</a>
    <a href="project6.html">Project 6</a>
  </nav>
</header>
    <h1>Final Project: NeRF</h1>
    <h2>Alp Eren Ozdarendeli</h2>    
    <div class="project-overview">
        <h2>Part 1: Fit a Neural Field to a 2D Image</h2>
            <p> In this section, I implement Neural Radiance Field in 2 dimensions. In 2 dimensions, we don't have the concept of radiance so essentially Neural Radiance Field in 2 dimensions reduces to Neural Field, in which we represent 2D by mapping (u,v) to (R,G,B) - converting the pixel coordinate to RGB values. For this, I created Multilayer Perceptron and Sinusoidal Positional Encoding with given architecture. For Multilayer Perceptron, I used 4 hidden layers(size 256) with RELU and a linear layer(size 3) with sigmoid. Also, I created a dataloader that randomly samples certain number of pixels from the image at each iteration. To determine the correct hyperparameters, I have explored different values for learning rate and max frequency L for the given image.  As the baseline, I used the hyperparameters layers=4, hidden dim=256, L=10, LR=1e-2. Firstly, I explored the effect of max frequency L. Here are my results for the baseline, L=20, LR=5: </p>
                <div class="image-grid">
            <div class="image-container">
                <img src="proj5images/baseline_psnrr.png" alt="taj.jpg">
                <p class="image-subtitle"> Baseline PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/l5_psnrr.png" alt="taj.jpg">
                <p class="image-subtitle">L=5 PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/l20_psnrr.png" alt="taj.jpg">
                <p class="image-subtitle">L=20 PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/baselinef.png" alt="taj.jpg">
                <p class="image-subtitle"> Baseline Final Image</p>
            </div>
            <div class="image-container">
                <img src="proj5images/l5f.png" alt="taj.jpg">
                <p class="image-subtitle">L=5 Final Image</p>
            </div>
            <div class="image-container">
                <img src="proj5images/l20f.png" alt="taj.jpg">
                <p class="image-subtitle">L=20 Final Image</p>
            </div>
                    </div>
        <div class="clear-float"></div>
        <p> From the images, it is clear that reducing the max frequency from 10 to 5 resulted in worse performance. Also, the increase from 10 to 20 did not improve the model's performance visibly, PSNR curves seemed to converge to similar value. Thus, I decided to use L=10. </p>
        <p> As another hyperparameter, I varying the learning rate. Here are my results for the  baseline, LR=0.02, L=0.005:</p>
                <div class="image-grid">
            <div class="image-container">
                <img src="proj5images/baseline_psnrr.png" alt="taj.jpg">
                <p class="image-subtitle"> Baseline PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/lr11.png" alt="taj.jpg">
                <p class="image-subtitle">LR= 0.005 PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/lr0011.png" alt="taj.jpg">
                <p class="image-subtitle">LR=0.02 PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/baselinef.png" alt="taj.jpg">
                <p class="image-subtitle"> Baseline Final Image</p>
            </div>
            <div class="image-container">
                <img src="proj5images/lr0.005f.png" alt="taj.jpg">
                <p class="image-subtitle">LR=0.005 Final Image</p>
            </div>
            <div class="image-container">
                <img src="proj5images/lr2f.png" alt="taj.jpg">
                <p class="image-subtitle">LR = 0.02 Final Image</p>
            </div>
                    </div>
        <div class="clear-float"></div>
        <p> Training curves look pretty similar, but halving the learning rate caused a slight drop in performance. Also, for learning rate 2e-2, I think the final image has worse quality than the final image for the baseline.</p>
        <p>Here are my results for the given image, sampled at every 400 iterations. I trained the model for 2001 iterations. For this training, I used the following hyperparameters, layers=4, hidden dim=256, L=10, LR=1e-2:</p>
        <div class="image-grid">
            <div class="image-container">
                <img src="proj5images/baseline_psnrr.png" alt="taj.jpg">
                <p class="image-subtitle"> Training PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/br1.png" alt="taj.jpg">
                <p class="image-subtitle">T=0</p>
            </div>
            <div class="image-container">
                <img src="proj5images/br2.png" alt="taj.jpg">
                <p class="image-subtitle">T=400</p>
            </div>
            <div class="image-container">
                <img src="proj5images/br3.png" alt="taj.jpg">
                <p class="image-subtitle">T=800</p>
            </div>
            <div class="image-container">
                <img src="proj5images/br4.png" alt="taj.jpg">
                <p class="image-subtitle">T=1200</p>
            </div>
            <div class="image-container">
                <img src="proj5images/br5.png" alt="taj.jpg">
                <p class="image-subtitle">T=1600</p>
            </div>
                        <div class="image-container">
                <img src="proj5images/br6.png" alt="taj.jpg">
                <p class="image-subtitle">T=2000</p>
            </div>
                    </div>
        <div class="clear-float"></div>
        <p>I also ran my training loop for another image of my choosing, a crocodile. For this training, I used the following hyperparameters, layers=4, hidden dim=256, L=10, LR=5e-3:. Here are my results for the image, and my training curve: </p>    
                <div class="image-grid">
                            <div class="image-container">
                <img src="proj5images/images.jpeg" alt="taj.jpg">
                <p class="image-subtitle"> Original Image</p>
            </div>
            <div class="image-container">
                <img src="proj5images/crocodile.png" alt="taj.jpg">
                <p class="image-subtitle"> Training PSNR Curve</p>
            </div>
            <div class="image-container">
                <img src="proj5images/croc1.png" alt="taj.jpg">
                <p class="image-subtitle">T=0</p>
            </div>
            <div class="image-container">
                <img src="proj5images/croc2.png" alt="taj.jpg">
                <p class="image-subtitle">T=400</p>
            </div>
            <div class="image-container">
                <img src="proj5images/croc3.png" alt="taj.jpg">
                <p class="image-subtitle">T=800</p>
            </div>
            <div class="image-container">
                <img src="proj5images/croc4.png" alt="taj.jpg">
                <p class="image-subtitle">T=1200</p>
            </div>
            <div class="image-container">
                <img src="proj5images/croc5.png" alt="taj.jpg">
                <p class="image-subtitle">T=1600</p>
            </div>
                        <div class="image-container">
                <img src="proj5images/croc6.png" alt="taj.jpg">
                <p class="image-subtitle">T=2000</p>
            </div>
                    </div>
        <h2>Part 2: Fit a Neural Radiance Field from Multi-view Images</h2>
        <p> In this part, I will use a neural radiance field to represent 3D. For this, I will use inverse rendering for multi-view calibrated images.</p>
        <h2>Part 2.1: Create Rays from Cameras</h2>
        <p> In this part, I create two functions for sampling, sample_rays(self, numberofrays, numberofimages) and sample_along_rays(rays_o, rays_d, perturb). I defined the sample_rays function under RaysData class. Similar to Part 1, sample_rays randomly samples numberofrays from numberofimages. sample_along_rays is used for sampling points along the obtained rays, and optionally perturbed in training so that every location along the ray would be covered.</p>
        <h2>Part 2.2: Sampling</h2>
        <p> In this part, I defined the required functions, transform(c2w, x_c), pixel_to_camera(c2w, x_c), pixel_to_ray(K, c2w, x_c). transform function takes in camera coordinates and obtains the corresponding world coordinates using c2w matrix. pixel_to_camera takes in pixel coordinates and obtains camera coordinates, using the intrinsic matrix K. pixel_to_ray takes in world coordinates, and by using the other functions, obtains rays with origin and normalized directions.</p>
        <h2>Part 2.3: Putting the Dataloading All Together</h2>
        <p>In this part, I put everything I did so far together to visualize the given tests:</p>
                <div class="image-grid">
            <div class="image-container">
                <img src="proj5images/sa1.png" alt="taj.jpg">
                <p class="image-subtitle"> Cameras, 100 Rays, Samples</p>
            </div>
            <div class="image-container">
                <img src="proj5images/sa2.png" alt="taj.jpg">
                <p class="image-subtitle">Random rays from the first image</p>
            </div>
                                <div class="image-container">
                <img src="proj5images/sa3.png" alt="taj.jpg">
                <p class="image-subtitle">Random rays from the top left corner of the image</p>
            </div>
                    </div>
        <div class="clear-float"></div>
        <h2>Part 2.4: Neural Radiance Field</h2>
        <p>In this part, I implement the NeRF architecture. It is similar to MLP but there are some changes as we have samples in 3D, and want to predict density and color of the samples. One of the main changes are now the MLP is deeper because the task we are trying to implement is harder. Also, we are not only going to output color but also density for the inputs, which are 3D world coordinates and ray direction. For this, I will use the direction as the condition to output colors. Lastly, I inject the input to the middle of the MLP after getting it through PE I defined earlier to make model not forget about the input as the neural network got deeper. For this part, I used the given architecture:</p>
                        <div class="image-gr">
            <div class="image-container">
                <img src="proj5images/mlp_nerf.png" alt="taj.jpg">
            </div>
         </div>
        <div class="clear-float"></div>
                <h2>Part 2.5:  Volume Rendering</h2>
        <p> In order to obtain render colors, I used the given volume rendering equation, which combined the batches of samples from each ray:</p>
                                <div class="image-gr">
            <div class="image-container">
                <img src="proj5images/volrend.png" alt="taj.jpg">
            </div>
         </div>
        <div class="clear-float"></div>
        <p>Here is the visualized training, predictions shown for each 100 iterations. I used the given hyperparameters, and trained the model for 1000 iterations. Also, I provide the PSNR curve on the validation set (every 10 iterations) and the training set.</p>
                        <div class="image-gr">
        <div class="image-container">
            <img src="proj5images/psnrn.png" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
                        <div class="image-gi">
                                    <div class="image-container">
            <img src="proj5images/validation0.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation100.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation200.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation300.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation400.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation500.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation600.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation700.png" alt="taj.jpg">
        </div>
                                    <div class="image-container">
            <img src="proj5images/validation800.png" alt="taj.jpg">
        </div>
                                                                <div class="image-container">
            <img src="proj5images/validation900.png" alt="taj.jpg">
        </div>
                                                                <div class="image-container">
            <img src="proj5images/validation990.png" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
        <p>Combining everything together, here is a spherical rendering of lego using the provided camera extrinsics:</p>
                <div class="image-gr">
        <div class="image-container">
            <img src="proj5images/leg.gif" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
        <h2>B&W: Background Coloring</h2>
        <p>For bells and whistles, I implement the background color. The background color is added to the rendered scene by treating it as the color seen when a ray passes through all objects without being blocked:</p>
        <div class="image-gr">
        <div class="image-container">
            <img src="proj5images/lego_backgroun.gif" alt="taj.jpg">
        </div>
        </div>
        <div class="clear-float"></div>
